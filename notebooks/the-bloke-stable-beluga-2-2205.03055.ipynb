{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e50065-dd79-48b6-9bc3-87eb6522a15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.6)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
      "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.8.8)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.2)\n",
      "Requirement already satisfied: accelerate>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.21.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.14.4)\n",
      "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.0.1+cu118)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (5.9.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (15.0.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.8.5)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.2.1)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode tiktoken transformers einops auto-gptq sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5a187-7c86-4ea4-863a-55817112cfb5",
   "metadata": {},
   "source": [
    "## Time to install packages 4 mins 0 seconds\n",
    "## Time started: 23:59:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4255ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "import itertools\n",
    "import tiktoken\n",
    "import ast\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af9777c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, logging\n",
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "\n",
    "model_name_or_path = \"TheBloke/StableBeluga2-70B-GPTQ\"\n",
    "model_basename = \"gptq_model-4bit--1g\"\n",
    "model_name = 'StableBeluga2'\n",
    "file_code = '2205.03055'\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
    "        model_basename=model_basename,\n",
    "        inject_fused_attention=False, # Required for Llama 2 70B models at this time.\n",
    "        use_safetensors=True,\n",
    "        trust_remote_code=False,\n",
    "        device=\"cuda:0\",\n",
    "        use_triton=use_triton,\n",
    "        quantize_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f3d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(prompt_template, model=\"gpt-3.5-turbo\"):\n",
    "    return len(tokenizer(prompt_template, return_tensors='pt').input_ids.cuda().tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604d244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_messages(text):\n",
    "    # This is a placeholder for your actual implementation\n",
    "    return text.split(\"\\n\")\n",
    "\n",
    "def split_into_chunks(text, max_tokens=2000):\n",
    "    messages = split_into_messages(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_tokens = 0\n",
    "    for message in messages:\n",
    "        message_tokens = num_tokens_from_messages(message, model=\"gpt-3.5-turbo\")\n",
    "        if current_tokens + message_tokens > max_tokens:\n",
    "            # If adding this message would exceed the max tokens, start a new chunk\n",
    "            chunks.append('\\n'.join(current_chunk))\n",
    "            current_chunk = [message]\n",
    "            current_tokens = message_tokens\n",
    "        else:\n",
    "            # Otherwise, add the message to the current chunk\n",
    "            current_chunk.append(message)\n",
    "            current_tokens += message_tokens\n",
    "    # Don't forget the last chunk!\n",
    "    if current_chunk:\n",
    "        chunks.append('\\n'.join(current_chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e285df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_string(input_str):\n",
    "    if \"</s>\" in input_str:\n",
    "        return input_str\n",
    "    else:\n",
    "        last_comma_index = input_str.rfind(',')\n",
    "        if last_comma_index == -1:\n",
    "            return input_str  # No comma found, return the string as is\n",
    "        else:\n",
    "            return input_str[:last_comma_index] + '}' + input_str[last_comma_index+1:]\n",
    "        \n",
    "def get_json_of_string(incorrect, pattern=r'\\{[^\\}]*\\}'):\n",
    "    match = re.search(r'{(.*)}', incorrect, re.DOTALL)\n",
    "    if match:\n",
    "        return \"{\" + match.group(1).replace('{', '[').replace('}', ']') + \"}\"\n",
    "    else:\n",
    "        return \"{}\"\n",
    "\n",
    "\n",
    "def string_to_dict(my_string):\n",
    "    # Load the JSON string into a list of tuples\n",
    "    tuples_list = json.JSONDecoder(object_pairs_hook=list).decode(my_string)\n",
    "\n",
    "    # Create a new dictionary to hold the final result\n",
    "    final_dict = {}\n",
    "\n",
    "    # Iterate over the list of tuples\n",
    "    for key, value in tuples_list:\n",
    "        # If the key is already in the final dictionary, append the value\n",
    "        # to the list of values for that key\n",
    "        if key in final_dict:\n",
    "            # Ensure the value is in a list form\n",
    "            if not isinstance(final_dict[key], list):\n",
    "                final_dict[key] = [final_dict[key]]\n",
    "            final_dict[key].append(value)\n",
    "        else:\n",
    "            # If the key is not in the final dictionary, add it with the value\n",
    "            final_dict[key] = value\n",
    "\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c1858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dictionaries(dict1, dict2):\n",
    "    union_dict = dict1.copy()\n",
    "\n",
    "    for key, value in dict2.items():\n",
    "        if key in union_dict:\n",
    "            if isinstance(union_dict[key], list):\n",
    "                if value not in union_dict[key]:\n",
    "                    union_dict[key].append(value)\n",
    "            else:\n",
    "                if union_dict[key] != value:\n",
    "                    union_dict[key] = [union_dict[key], value]\n",
    "        else:\n",
    "            union_dict[key] = value\n",
    "\n",
    "    return union_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff36d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_tags(element):\n",
    "    if isinstance(element, NavigableString):\n",
    "        return element\n",
    "    if element.name == 'mi':\n",
    "        return str(element)\n",
    "    return ''.join(get_text_from_tags(child) for child in element.children)\n",
    "\n",
    "def parse_html(file_path, clean=True):\n",
    "    with open(file_path, 'r', encoding='utf-8') as html_file:\n",
    "        soup = BeautifulSoup(html_file, 'html.parser')\n",
    "\n",
    "    texts = get_text_from_tags(soup)\n",
    "    if clean:\n",
    "        matches = re.findall(r'<mi(.*?)</mi>', texts)\n",
    "        for match in matches:\n",
    "            original_string = f'<mi{match}</mi>'\n",
    "            replaced_string = re.sub(r'<.*?>(.*?)</.*?>', r'<|\\1|>', original_string)\n",
    "            texts = texts.replace(original_string, replaced_string)\n",
    "\n",
    "    return texts\n",
    "\n",
    "# call the function with your HTML file path\n",
    "page = parse_html(f'{file_code}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9f95a7-690d-49a1-947e-2d1c107a5f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(prompt):\n",
    "    return f'''### SYSTEM:\\n{prompt[0]['content']}\\n\\n\n",
    "### USER:\\n{prompt[1]['content']}\\n\\n\n",
    "### ASSISTANT:\\n{prompt[2]['content']}\\n\\n\n",
    "### USER:\\n{prompt[3]['content']}\\n\\n\n",
    "### ASSISTANT:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d0568d3-d765-4c53-ac27-c67650dad1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_pattern(input_string):\n",
    "    pattern = r\"<\\|[^<\\|>]*\\|>\"\n",
    "    if re.search(pattern, input_string):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0f85cb-e25a-4a21-81a4-c8c143a47c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(output):\n",
    "    pos = output.index('Do not include the angle brackets in the dictionary')\n",
    "    end_of_string = output[pos:]\n",
    "    print(end_of_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf7ee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1276 prompt tokens counted.\n"
     ]
    }
   ],
   "source": [
    "text = page\n",
    "chunks = split_into_chunks(text, max_tokens=512)\n",
    "i = 0\n",
    "\n",
    "while not contains_pattern(chunks[i]):\n",
    "    i += 1\n",
    "print(i)\n",
    "\n",
    "question = chunks[i]\n",
    "\n",
    "actual_total_tokens = 0\n",
    "completion_tokens = 0\n",
    "prompt_tokens = 0\n",
    "\n",
    "prompt = [\n",
    "        {'role': 'system',\n",
    "         'content': 'You are a helpful research assistant tasked with converting long paragraphs into a JSON '\n",
    "                    'dictionary. The goal is to identify and classify each individual mathematical symbol, variable,'\n",
    "                    ' and identifier in the text marked between \"<||>\". The dictionary should store the identifiers as '\n",
    "                    'keys and their corresponding definitions as values in an array format. '},\n",
    "        {'role': 'system', 'name': 'example_user', 'content': '''A relational model is a triple <|M|>′=(<|X|>,<|R|>,\n",
    "        <|v|>), where <|X|> is a set of states, <|R|><|⊆|><|X|><|×|><|X|> is a binary relation on <|X|>, \n",
    "        and <|v|>:<|𝖯𝗋𝗈𝗉|>→2<|X|> is a valuation. Given a relational model <|M|>′, the satisfaction relation between \n",
    "        points <|x<|∈<|X<| and formulas <|φ<|∈<|ℒ<|<|𝖪𝖠<| is defined inductively by <|M|>′,<|x|>⊨<|𝖪|><|φ|>⇔ for all \n",
    "        <|y|>∈<|X|>,<|x|><|R|><|y|> implies <|M|>′,<|y|>⊨<|φ|><|M|>′,<|x|>⊨<|𝖠|><|φ|><||>⇔ for all <|y|>∈<|X|>,\n",
    "        <|M|>′,<|y|>⊨<|φ|>'''},\n",
    "        {'role': 'system', 'name': 'example_assistant', 'content': '''identifiers = {\n",
    "            \"M\": [\"Model\", \"Expertise Model\"],\n",
    "            \"M'\": \"Relational model\",\n",
    "            \"X\": \"Set of states\",\n",
    "            \"R\": \"Binary relation on X\",\n",
    "            \"v\": \"Valuation\",\n",
    "            \"𝖯𝗋𝗈𝗉\": \"Set of propositions\",\n",
    "            \"M'\": \"Relational model\",\n",
    "            \"x\": \"Point in X\",\n",
    "            \"φ\": \"Formula in 𝖪𝖠\",\n",
    "            \"ℒ_{𝖪𝖠}\": \"Set of formulas\",\n",
    "            \"𝖪\": \"Modal operator K\",\n",
    "            \"𝖠\": \"Modal operator A\",\n",
    "            \"y\": \"Point in X\",\n",
    "            \"⊨\": \"Satisfaction relation\",\n",
    "            \"⇔\": \"If and only if operator\",\n",
    "            \"∈\": \"Element of a set\",\n",
    "            \"⊆\": \"Subset of a set\",\n",
    "            \"×\": \"Cartesian product operator\",\n",
    "            \"→\": \"Function or implication operator\",\n",
    "            \"for all\": \"Universal quantifier\"\n",
    "            }'''},\n",
    "        {'role': 'user', 'content': f'Generate a JSON dictionary for the following text\\n```txt\\n{question}```. '\n",
    "                                    'Only consider the mathematical identifiers inside \"<||>\" for the dictionary. '\n",
    "                                    'Do not consider any other identifier other than those marked. Consider all the '\n",
    "                                    'identifiers individually. Do not skip any identifier, mention all the identifiers '\n",
    "                                    'inside \"<||>\" in your dictionary. Do not include the angle brackets in the '\n",
    "                                    'dictionary.'}\n",
    "    ]\n",
    "\n",
    "\n",
    "open_prompt = get_prompt(prompt)\n",
    "\n",
    "prompt_size = num_tokens_from_messages(open_prompt)\n",
    "print(f\"{prompt_size} prompt tokens counted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612640fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TheBloke/StableBeluga2-70B-GPTQ\n",
      "Do not include the angle brackets in the dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " identifiers = {\n",
      "            \"Binbin Yang\": \"Author 1\",\n",
      "            \"Xinchi Deng\": \"Author 1\",\n",
      "            \"Han Shi\": \"Author 2\",\n",
      "            \"Changlin Li\": \"Author 3\",\n",
      "            \"Gengwei Zhang\": \"Author 1\",\n",
      "            \"Hang Xu\": \"Author 4\",\n",
      "            \"Shen Zhao\": \"Author 1\",\n",
      "            \"Liang Lin\": \"Author 1\",\n",
      "            \"Xiaodan Liang\": \"Author 1\",\n",
      "            \"Sun Yat-sen University\": \"Affiliation 1\",\n",
      "            \"The Hong Kong University of Science and Technology\": \"Affiliation 2\",\n",
      "            \"ReLER, AAII, UTS\": \"Affiliation 3\",\n",
      "            \"Huawei Noah’s Ark Lab\": \"Affiliation 4\",\n",
      "            \"yangbb3\": \"Email 1\",\n",
      "            \"dengxch5\": \"Email 1\",\n",
      "            \"hshiac\": \"Email 2\",\n",
      "            \"zhaosh35\": \"Email 1\",\n",
      "            \"changlinli.ai\": \"Email 3\",\n",
      "            \"zgwdavid\": \"Email 3\",\n",
      "            \"chromexbjxh\": \"Email 3\",\n",
      "            \"xdliang328\": \"Email 3\",\n",
      "            \"linliang\": \"Email 4\",\n",
      "            \"Equal contribution\": \"Author contribution\",\n",
      "            \"Corresponding author\": \"Author contribution\",\n",
      "            \"Continual Object Detection\": \"Title\",\n",
      "            \"Prototypical Task Correlation Guided Gating Mechanism\": \"Title\",\n",
      "            \"Abstract\": \"Section\",\n",
      "            \"Continual learning\": \"Topic\",\n",
      "            \"Continual classification\": \"Topic\",\n",
      "            \"Continual object detection\": \"Topic\",\n",
      "            \"ROSETTA\": \"Framework\",\n",
      "            \"Unified framework\": \"Framework\",\n",
      "            \"Task-aware gates\": \"Framework\",\n",
      "            \"Sub-models\": \"Framework\",\n",
      "            \"Specific tasks\": \"Framework\"\n",
      "            }</s>\n",
      "Time taken: 0:00:42.999714\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using {model_name_or_path}\")\n",
    "start_time = datetime.now()\n",
    "\n",
    "input_ids = tokenizer(open_prompt, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.5, max_new_tokens=512)\n",
    "output_string = tokenizer.decode(output[0])\n",
    "print_output(output_string)\n",
    "\n",
    "total_time_taken = datetime.now() - start_time\n",
    "print(f\"Time taken: {total_time_taken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507e7993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761 485 1276\n"
     ]
    }
   ],
   "source": [
    "actual_total_tokens += num_tokens_from_messages(output_string)\n",
    "completion_tokens += num_tokens_from_messages(output_string) - num_tokens_from_messages(open_prompt)\n",
    "prompt_tokens += num_tokens_from_messages(open_prompt)\n",
    "print(actual_total_tokens, completion_tokens, prompt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff56fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Safely convert the dictionary string to a dictionary using json.loads()\n",
    "try:\n",
    "    ind = output_string.index('Do not include the angle brackets in the dictionary.')\n",
    "    correct_output_string = modify_string(output_string[ind:])\n",
    "    dic_output_string = get_json_of_string(correct_output_string)\n",
    "    dictionary = [string_to_dict(dic_output_string)]\n",
    "except Exception as e:\n",
    "    dictionary = [{}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acbf76ad-2acb-41dc-be3d-aab9c19c15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Binbin Yang': 'Author 1', 'Xinchi Deng': 'Author 1', 'Han Shi': 'Author 2', 'Changlin Li': 'Author 3', 'Gengwei Zhang': 'Author 1', 'Hang Xu': 'Author 4', 'Shen Zhao': 'Author 1', 'Liang Lin': 'Author 1', 'Xiaodan Liang': 'Author 1', 'Sun Yat-sen University': 'Affiliation 1', 'The Hong Kong University of Science and Technology': 'Affiliation 2', 'ReLER, AAII, UTS': 'Affiliation 3', 'Huawei Noah’s Ark Lab': 'Affiliation 4', 'yangbb3': 'Email 1', 'dengxch5': 'Email 1', 'hshiac': 'Email 2', 'zhaosh35': 'Email 1', 'changlinli.ai': 'Email 3', 'zgwdavid': 'Email 3', 'chromexbjxh': 'Email 3', 'xdliang328': 'Email 3', 'linliang': 'Email 4', 'Equal contribution': 'Author contribution', 'Corresponding author': 'Author contribution', 'Continual Object Detection': 'Title', 'Prototypical Task Correlation Guided Gating Mechanism': 'Title', 'Abstract': 'Section', 'Continual learning': 'Topic', 'Continual classification': 'Topic', 'Continual object detection': 'Topic', 'ROSETTA': 'Framework', 'Unified framework': 'Framework', 'Task-aware gates': 'Framework', 'Sub-models': 'Framework', 'Specific tasks': 'Framework'}]\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d18ab90-38c2-4724-9a03-239fc73078d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_loop(prompt):\n",
    "    return f'''### SYSTEM:\\n{prompt[0]['content']}\\n\\n\n",
    "### USER:\\n{prompt[1]['content']}\\n\\n\n",
    "### ASSISTANT:\\n{prompt[2]['content']}\\n\\n\n",
    "### SYSTEM:\\n{prompt[3]['content']}\\n\\n\n",
    "### USER:\\n{prompt[4]['content']}\\n\\n\n",
    "### ASSISTANT:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bab7543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of 38\n",
      "Iteration 1 of 38\n",
      "Iteration 2 of 38\n",
      "Iteration 3 of 38\n",
      "Iteration 4 of 38\n",
      "Iteration 5 of 38\n",
      "Iteration 6 of 38\n",
      "Iteration 7 of 38\n",
      "Iteration 8 of 38\n",
      "\n",
      "\n",
      "\n",
      "1615 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"𝒯\": \"Set of tasks\",\n",
      "    \"D_t\": \"Dataset for the tth task\",\n",
      "    \"X_t\": \"Input images for the tth task\",\n",
      "    \"Y_t\": \"Annotations for the tth task\",\n",
      "    \"C_t\": \"Recognized categories for the tth task\",\n",
      "    \"Catastrophic Forgetting\": \"Phenomenon of rapid performance degradation on previously learned tasks\"\n",
      "}</s>\n",
      "596 2891\n",
      "Actual total tokens till now: 3487\n",
      "Iteration 9 of 38\n",
      "\n",
      "New dictionary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1239 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " identifiers = {\n",
      "            \"ROSETTA\": \"Proposed method for continual object detection\",\n",
      "            \"GDC\": \"Task correlation guided Gating Diversity Controller\",\n",
      "            \"𝒆\": \"Class embeddings\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒇<|l|><|t|>\": \"Input feature map\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒇<|l|><|t|>\": \"Input feature map\",\n",
      "            \"𝒇<|l|><|t|>\": \"Input feature map\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"𝒆<|t|>\": \"Task embedding\",\n",
      "            \"\n",
      "1109 4130\n",
      "Actual total tokens till now: 5239\n",
      "Iteration 10 of 38\n",
      "\n",
      "\n",
      "\n",
      "1218 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"𝒇\": \"Input feature map\",\n",
      "    \"𝒇<|l|>\": \"Input feature map\",\n",
      "    \"𝒇<|l|><|t|>\": \"Input feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<\n",
      "1622 5348\n",
      "Actual total tokens till now: 6970\n",
      "Iteration 11 of 38\n",
      "\n",
      "\n",
      "\n",
      "1600 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"⊙\": \"Channel-wise multiplication\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map of gated convolution\",\n",
      "    \"F<|l|><|t|>\": \"Output of convolution\",\n",
      "    \"G<|l|><|t|>\": \"Channel gates of the lth layer\",\n",
      "    \"g<|l|>c<|t|>\": \"Channel gate of the lth layer\",\n",
      "    \"𝒆<|𝒕|>\": \"Learnable task embedding\",\n",
      "    \"C<|t|>\": \"Class embeddings\",\n",
      "    \"𝒆<|𝒕|>\": \"Task embedding\",\n",
      "    \"𝒇<|l|>\": \"Input feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "    \"𝒇<|l|>+1<|t|>\": \"Output feature map\",\n",
      "\n",
      "2135 6948\n",
      "Actual total tokens till now: 9083\n",
      "Iteration 12 of 38\n",
      "\n",
      "\n",
      "\n",
      "1812 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"g\": \"Channel gates\",\n",
      "    \"l\": \"Layer\",\n",
      "    \"c\": \"Channel\",\n",
      "    \"t\": \"Task\",\n",
      "    \"γ\": \"Threshold\",\n",
      "    \"x\": \"Input\",\n",
      "    \"y\": \"Output\",\n",
      "    \"D\": \"Dataset\",\n",
      "    \"val\": \"Validation set\",\n",
      "    \"I\": \"Indicator function\",\n",
      "    \"g^\": \"Static binary gate\"\n",
      "}</s>\n",
      "2237 8760\n",
      "Actual total tokens till now: 10997\n",
      "Iteration 13 of 38\n",
      "\n",
      "New dictionary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1242 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"𝕀\": \"Indicator function\",\n",
      "    \"𝒇\": \"Gated output feature for inference time\",\n",
      "    \"𝒈\": \"Activated channel weights\",\n",
      "    \"F\": \"Discretized binary gates\",\n",
      "    \"g\": \"Soft gates\",\n",
      "    \"c\": \"Number of classes\"\n",
      "}</s>\n",
      "2318 10002\n",
      "Actual total tokens till now: 12320\n",
      "Iteration 14 of 38\n",
      "\n",
      "\n",
      "\n",
      "1390 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"𝒇\": \"Gated output feature for inference time\",\n",
      "    \"𝒈\": \"Activated channel weights\",\n",
      "    \"F\": \"Discretized binary gates\",\n",
      "    \"g\": \"Soft gates\",\n",
      "    \"c\": \"Number of classes\",\n",
      "    \"𝔼\": \"Expected value\",\n",
      "    \"D\": \"Distribution\",\n",
      "    \"t\": \"Time\",\n",
      "    \"L\": \"Number of layers\",\n",
      "    \"𝑠𝑝𝑎𝑟𝑠𝑖𝑡𝑦\": \"Sparsity\",\n",
      "    \"𝑘𝑑\": \"Knowledge distillation\",\n",
      "    \"MSE\": \"Mean square error\",\n",
      "    \"𝒇~𝒙𝒕\": \"Feature map of teacher model\",\n",
      "    \"F~𝒙𝒕\": \"Traditional convolutional operation without gated module\"\n",
      "}</s>\n",
      "2551 11392\n",
      "Actual total tokens till now: 13943\n",
      "Iteration 15 of 38\n",
      "\n",
      "\n",
      "\n",
      "1457 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " identifiers = {\n",
      "            \"𝑑𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦\": \"Gating diversity loss\",\n",
      "            \"ℒ\": \"Entropy\"\n",
      "            }</s>\n",
      "2620 12849\n",
      "Actual total tokens till now: 15469\n",
      "Iteration 16 of 38\n",
      "\n",
      "\n",
      "\n",
      "1541 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"ℒ\": \"Entropy\",\n",
      "    \"𝑑𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦\": \"Gating diversity loss\",\n",
      "    \"l\": \"Layer\",\n",
      "    \"t\": \"Task\",\n",
      "    \"q\": \"Estimated ratio of newly activated gates\",\n",
      "    \"g\": \"Activated channel weights\",\n",
      "    \"𝕀\": \"Indicator function\",\n",
      "    \"η\": \"Hyper-parameter threshold\",\n",
      "    \"m\": \"Total number of previously inactivated channels\"\n",
      "}</s>\n",
      "2766 14390\n",
      "Actual total tokens till now: 17156\n",
      "Iteration 17 of 38\n",
      "\n",
      "\n",
      "\n",
      "1532 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " identifiers = {\n",
      "    \"t\": \"Task\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "    \"𝒑\": \"Prototype of the ith class\",\n",
      "    \"𝒑\": \"Prototype of the jth class\",\n",
      "    \"𝐌\": \"Class-to-class prototypical correlation matrix\",\n",
      "\n",
      "3279 15922\n",
      "Actual total tokens till now: 19201\n",
      "Iteration 18 of 38\n",
      "\n",
      "\n",
      "\n",
      "1915 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"C\": \"Categories\",\n",
      "    \"t\": \"Task\",\n",
      "    \"𝐌\": \"Class-to-task correlation\",\n",
      "    \"j\": \"Class\",\n",
      "    \"m\": \"Task\",\n",
      "    \"n\": \"Task\",\n",
      "    \"𝒑\": \"Class-to-task correlation\",\n",
      "    \"i\": \"Class\",\n",
      "    \"ℛ\": \"Class-to-task correlation\",\n",
      "    \"C\": \"Categories\",\n",
      "    \"𝒑\": \"Class-to-task correlation\"\n",
      "}</s>\n",
      "3406 17837\n",
      "Actual total tokens till now: 21243\n",
      "Iteration 19 of 38\n",
      "\n",
      "New dictionary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1181 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " identifiers = {\n",
      "            \"ℛ\": \"Prototypical task correlation\",\n",
      "            \"𝒑\": \"Task\",\n",
      "            \"𝒑_n\": \"Task n\",\n",
      "            \"𝒑_m\": \"Task m\",\n",
      "            \"GDC\": \"Gating diversity controller\",\n",
      "            \"ϕ\": \"Weight function\",\n",
      "            \"max\": \"Maximum operator\",\n",
      "            \"t\": \"Task t\",\n",
      "            \"t_1\": \"Task t_1\"\n",
      "            }</s>\n",
      "3525 19018\n",
      "Actual total tokens till now: 22543\n",
      "Iteration 20 of 38\n",
      "\n",
      "\n",
      "\n",
      "1189 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"ℒ\": \"Diversity\",\n",
      "    \"𝑑𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦\": \"Diversity\",\n",
      "    \"L\": \"Length\",\n",
      "    \"t\": \"Time\",\n",
      "    \"l\": \"Label\",\n",
      "    \"i\": \"Index\",\n",
      "    \"ϕ\": \"Weight function\",\n",
      "    \"𝒑\": \"Task\",\n",
      "    \"𝒑_t\": \"Task at time t\",\n",
      "    \"𝒑_i\": \"Task i\",\n",
      "    \"GDC\": \"Gating diversity controller\"\n",
      "}</s>\n",
      "3681 20207\n",
      "Actual total tokens till now: 23888\n",
      "Iteration 21 of 38\n",
      "\n",
      "\n",
      "\n",
      "1523 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"D\": \"Dataset\",\n",
      "    \"i\": \"Index\",\n",
      "    \"j\": \"Index\",\n",
      "    \"C\": \"Category\",\n",
      "    \"t\": \"Time\",\n",
      "    \"COCO\": \"COCO dataset\",\n",
      "    \"Pascal VOC\": \"Pascal VOC dataset\",\n",
      "    \"KITTI\": \"KITTI dataset\",\n",
      "    \"Kitchen\": \"Kitchen dataset\",\n",
      "    \"ROSETTA\": \"ROSETTA dataset\",\n",
      "    \"VOC\": \"VOC dataset\",\n",
      "    \"COCO-VOC\": \"COCO-VOC dataset\",\n",
      "    \"KITTI-Kitchen\": \"KITTI-Kitchen dataset\",\n",
      "    \"Pascal VOC 2007\": \"Pascal VOC 2007 dataset\"\n",
      "}</s>\n",
      "3867 21730\n",
      "Actual total tokens till now: 25597\n",
      "Iteration 22 of 38\n",
      "Iteration 23 of 38\n",
      "Iteration 24 of 38\n",
      "Iteration 25 of 38\n",
      "Iteration 26 of 38\n",
      "Iteration 27 of 38\n",
      "\n",
      "\n",
      "\n",
      "1835 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"ℒ\": \"Task correlation\",\n",
      "    \"𝑠𝑝𝑎𝑟𝑠𝑖𝑡𝑦\": \"Sparsity\",\n",
      "    \"𝑘𝑑\": \"Knowledge distillation\",\n",
      "    \"𝑑𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦\": \"Diversity\"\n",
      "}</s>\n",
      "3990 23565\n",
      "Actual total tokens till now: 27555\n",
      "Iteration 28 of 38\n",
      "\n",
      "New dictionary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1286 prompt tokens counted.\n",
      "\n",
      "Do not include the angle brackets in your dictionary.\n",
      "\n",
      "\n",
      "### ASSISTANT:\n",
      " {\n",
      "    \"𝐌\": \"Normalized prototypical correlation matrix of VOC→KITTI\",\n",
      "    \"VOC\": \"Visual Object Classes\",\n",
      "    \"KITTI\": \"KITTI dataset\",\n",
      "    \"𝚝𝚊𝚜𝚔𝟷\": \"COCO-VOC\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"COCO\": \"Microsoft Common Objects in Context\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�����������������\": \"KITTI-Kitchen\",\n",
      "    \"�������\n",
      "4388 24851\n",
      "Actual total tokens till now: 29239\n",
      "Iteration 29 of 38\n",
      "Iteration 30 of 38\n",
      "Iteration 31 of 38\n",
      "Iteration 32 of 38\n",
      "Iteration 33 of 38\n",
      "Iteration 34 of 38\n",
      "Iteration 35 of 38\n",
      "Iteration 36 of 38\n",
      "Iteration 37 of 38\n",
      "Time taken: 0:06:15.571642\n",
      "Total time taken: 0:06:58.571304\n",
      "29239 4388 24851\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "number_of_dictionaries = 0\n",
    "for chunk in chunks:\n",
    "    print(f\"Iteration {i} of {len(chunks)}\")\n",
    "    i += 1\n",
    "    if chunk == question:\n",
    "        continue\n",
    "    if not contains_pattern(chunk):\n",
    "        continue\n",
    "    question = chunk\n",
    "    \n",
    "    if prompt_size > 1600:\n",
    "        number_of_dictionaries += 1\n",
    "        print(\"\\nNew dictionary\\n\")\n",
    "        dictionary.append({})\n",
    "    \n",
    "    prompt = [\n",
    "            {'role': 'system',\n",
    "             'content': 'You are a helpful research assistant tasked with converting long paragraphs into a JSON '\n",
    "                        'dictionary. '\n",
    "                        'The goal is to identify and classify each individual mathematical symbol, variable, '\n",
    "                        'and identifier in the text marked between \"<||>\"'\n",
    "                        'The dictionary should store the identifiers as keys and their corresponding definitions as '\n",
    "                        'values in an array format. '},\n",
    "            {'role': 'system', 'name': 'example_user', 'content': '''A relational model is a triple <|M|>′=(<|X|>,<|R|>,\n",
    "            <|v|>), where <|X|> is a set of states, <|R|><|⊆|><|X|><|×|><|X|> is a binary relation on <|X|>, \n",
    "            and <|v|>:<|𝖯𝗋𝗈𝗉|>→2<|X|> is a valuation. Given a relational model <|M|>′, the satisfaction relation \n",
    "            between points <|x<|∈<|X<| and formulas <|φ<|∈<|ℒ<|<|𝖪𝖠<| is defined inductively by <|M|>′,\n",
    "            <|x|>⊨<|𝖪|><|φ|>⇔ for all <|y|>∈<|X|>,<|x|><|R|><|y|> implies <|M|>′,<|y|>⊨<|φ|><|M|>′,\n",
    "            <|x|>⊨<|𝖠|><|φ|><||>⇔ for all <|y|>∈<|X|>,<|M|>′,<|y|>⊨<|φ|>'''},\n",
    "            {'role': 'system', 'name': 'example_assistant', 'content': '''identifiers = {\n",
    "            \"M\": [\"Model\", \"Expertise Model\"],\n",
    "            \"M'\": \"Relational model\",\n",
    "            \"X\": \"Set of states\",\n",
    "            \"R\": \"Binary relation on X\",\n",
    "            \"v\": \"Valuation\",\n",
    "            \"𝖯𝗋𝗈𝗉\": \"Set of propositions\",\n",
    "            \"M'\": \"Relational model\",\n",
    "            \"x\": \"Point in X\",\n",
    "            \"φ\": \"Formula in 𝖪𝖠\",\n",
    "            \"ℒ_{𝖪𝖠}\": \"Set of formulas\",\n",
    "            \"𝖪\": \"Modal operator K\",\n",
    "            \"𝖠\": \"Modal operator A\",\n",
    "            \"y\": \"Point in X\",\n",
    "            \"⊨\": \"Satisfaction relation\",\n",
    "            \"⇔\": \"If and only if operator\",\n",
    "            \"∈\": \"Element of a set\",\n",
    "            \"⊆\": \"Subset of a set\",\n",
    "            \"×\": \"Cartesian product operator\",\n",
    "            \"→\": \"Function or implication operator\",\n",
    "            \"for all\": \"Universal quantifier\"\n",
    "            }'''},\n",
    "            {'role': 'system',\n",
    "             'content': f'Given is already a pre existing dictionary. Your job is to extend this dictionary. Do not '\n",
    "                        f'remove any pre existing definitions from this dictionary.'\n",
    "                        f'\\n{dictionary[number_of_dictionaries]}. If there is nothing to mention, reply with an empty '\n",
    "                        f'dictionary'},\n",
    "            {'role': 'user', 'content': f'Generate a JSON dictionary for the following text: {question}. '\n",
    "                                        'Only consider the mathematical identifiers inside \"<||>\" for the dictionary. '\n",
    "                                        'Do not consider any other identifier other than those marked. '\n",
    "                                        'Consider all the identifiers individually. Do not skip any identifier, mention'\n",
    "                                        ' all the identifiers inside \"<||>\" in your dictionary. '\n",
    "                                        'Do not include the angle brackets in your dictionary.'}\n",
    "        ]\n",
    "    \n",
    "    open_prompt = get_prompt_loop(prompt)\n",
    "    \n",
    "    prompt_size = num_tokens_from_messages(open_prompt)\n",
    "    print(f\"\\n\\n\\n{prompt_size} prompt tokens counted.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            input_ids = tokenizer(open_prompt, return_tensors='pt').input_ids.cuda()\n",
    "            output = model.generate(inputs=input_ids, temperature=0.5, max_new_tokens=512, repetition_penalty=1.05)\n",
    "            output_string = tokenizer.decode(output[0])\n",
    "            \n",
    "            actual_total_tokens += num_tokens_from_messages(output_string)\n",
    "            completion_tokens += num_tokens_from_messages(output_string) - num_tokens_from_messages(open_prompt)\n",
    "            prompt_tokens += num_tokens_from_messages(open_prompt)\n",
    "\n",
    "            ind = output_string.index('Do not include the angle brackets in your dictionary.')\n",
    "            print(output_string[ind:])\n",
    "            \n",
    "            print(completion_tokens, prompt_tokens)\n",
    "    \n",
    "            print(f\"Actual total tokens till now: {actual_total_tokens}\")\n",
    "\n",
    "            try:\n",
    "                correct_output_string = modify_string(output_string[ind:])\n",
    "                dic_output_string = get_json_of_string(correct_output_string)\n",
    "                new_dictionary = string_to_dict(dic_output_string)\n",
    "            except Exception as e:\n",
    "                print(\"INCORRECT DICTIONARY\")\n",
    "            dictionary[number_of_dictionaries] = merge_dictionaries(dictionary[number_of_dictionaries], new_dictionary)\n",
    "            \n",
    "            break\n",
    "        except Exception as e:\n",
    "            number_of_dictionaries += 1\n",
    "            dictionary.append({})\n",
    "            print(f\"Exception occurred: {e}\")\n",
    "            print(\"Retrying...\")\n",
    "total_time_taken += (datetime.now() - start_time)\n",
    "print(f\"Time taken: {datetime.now() - start_time }\")\n",
    "print(f\"Total time taken: {total_time_taken}\")\n",
    "print(actual_total_tokens, completion_tokens, prompt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04278ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "for dic in dictionary:\n",
    "    dct = merge_dictionaries(dct, dic)\n",
    "# pprint.pprint(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4212dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ROSETTA': '['Framework', 'Proposed method for continual object detection', 'ROSETTA dataset']'\n",
      "'GDC': '['Task correlation guided Gating Diversity Controller', 'Gating diversity controller']'\n",
      "'𝒆<|t|>': '['Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding', 'Task embedding']'\n",
      "'𝒇<|l|><|t|>': '['Input feature map', 'Input feature map', 'Input feature map']'\n",
      "'𝒇': '['Input feature map', 'Gated output feature for inference time']'\n",
      "'𝒇<|l|>+1<|t|>': '['Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', ['Output feature map of gated convolution', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map', 'Output feature map']]'\n",
      "'𝒆<|𝒕|>': '['Learnable task embedding', 'Task embedding']'\n",
      "'g': '['Channel gates', ['Soft gates', 'Activated channel weights']]'\n",
      "'l': '['Layer', 'Label']'\n",
      "'c': '['Channel', 'Number of classes']'\n",
      "'t': '['Task', ['Time', 'Task'], ['Task t', 'Time']]'\n",
      "'D': '['Dataset', 'Distribution']'\n",
      "'L': '['Number of layers', 'Length']'\n",
      "'𝑑𝑖𝑣𝑒𝑟𝑠𝑖𝑡𝑦': '['Gating diversity loss', 'Diversity']'\n",
      "'ℒ': '['Entropy', ['Diversity', 'Task correlation']]'\n",
      "'m': '['Total number of previously inactivated channels', 'Task']'\n",
      "'𝒑': '['Prototype of the ith class', 'Prototype of the ith class', 'Prototype of the jth class', 'Prototype of the ith class', 'Prototype of the jth class', 'Prototype of the ith class', 'Prototype of the jth class', 'Prototype of the ith class', 'Prototype of the jth class', 'Prototype of the ith class', 'Prototype of the jth class', 'Prototype of the ith class', 'Prototype of the jth class', 'Prototype of the ith class', 'Prototype of the jth class', 'Prototype of the ith class', 'Prototype of the jth class', ['Class-to-task correlation', 'Class-to-task correlation'], 'Task']'\n",
      "'𝐌': '['Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-class prototypical correlation matrix', 'Class-to-task correlation', 'Normalized prototypical correlation matrix of VOC→KITTI']'\n",
      "'C': '['Categories', 'Categories', 'Category']'\n",
      "'j': '['Class', 'Index']'\n",
      "'i': '['Class', 'Index']'\n",
      "'ℛ': '['Class-to-task correlation', 'Prototypical task correlation']'\n",
      "'COCO': '['COCO dataset', 'Microsoft Common Objects in Context']'\n",
      "'VOC': '['VOC dataset', 'Visual Object Classes']'\n",
      "'�����������������': '['KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen', 'KITTI-Kitchen']'\n"
     ]
    }
   ],
   "source": [
    "for key, value in dct.items():\n",
    "    if type(value) == list:\n",
    "        print(f\"'{key}': '{value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed252bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(input_list):\n",
    "    output_list = []\n",
    "    for i in input_list:\n",
    "        if isinstance(i, list):\n",
    "            output_list.extend(flatten_list(i))\n",
    "        else:\n",
    "            output_list.append(i)\n",
    "    return output_list\n",
    "\n",
    "\n",
    "def remove_duplicates(input_list):\n",
    "    output_list = []\n",
    "    for item in input_list:\n",
    "        if item not in output_list:\n",
    "            output_list.append(item)\n",
    "    if len(output_list) == 1:\n",
    "        return output_list[0]\n",
    "    return output_list\n",
    "\n",
    "\n",
    "def process_value(v):\n",
    "    if isinstance(v, str):\n",
    "        new_v = v.replace('$', '')\n",
    "        while '\\\\\\\\' in new_v:\n",
    "            new_v = new_v.replace('\\\\\\\\', '\\\\').replace('\\n', '')\n",
    "    else:  # Assuming it's a list\n",
    "        new_v = flatten_list([process_value(val) for val in v])\n",
    "        \n",
    "    return remove_duplicates(new_v) if isinstance(new_v, list) else new_v\n",
    "\n",
    "\n",
    "def reduce_pairs(dictionary):\n",
    "    new_dict = {}\n",
    "    for k, v in dictionary.items():\n",
    "        # reduce key backslashes\n",
    "        new_k = k.replace('$', '')\n",
    "        while '\\\\\\\\' in new_k:\n",
    "            new_k = new_k.replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "        # process value\n",
    "        new_v = process_value(v)\n",
    "\n",
    "        new_dict[new_k] = new_v\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c8083f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_without_backslashes = reduce_pairs(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab472ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pprint.pprint(dict_without_backslashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b426f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_json = dict_without_backslashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dec9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{file_code}_mcdict.json', 'r', encoding='utf-8') as f:\n",
    "    mc_dict_original = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4284b146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to create a hex code (a binary representation of the key)\n",
    "def get_hex_code(key):\n",
    "    return key.encode().hex()\n",
    "\n",
    "mc_dict_original['_author'] = model_name_or_path\n",
    "\n",
    "# Iterate over your dictionary and fill the new one\n",
    "for key, values in parsed_json.items():\n",
    "    # Determine the base key and the affix\n",
    "    base_key = re.match(r\"^[^*'_^,(\\[]*\", key).group()\n",
    "    affix = key[len(base_key):]\n",
    "\n",
    "    hex_code = get_hex_code(base_key)\n",
    "    values = values if isinstance(values, list) else [values]\n",
    "\n",
    "    if hex_code in mc_dict_original[\"concepts\"]:\n",
    "        k = list(mc_dict_original[\"concepts\"][hex_code][\"identifiers\"].keys())[0]\n",
    "        new_identifier = []\n",
    "        for value in values:\n",
    "            mc_dict_original[\"concepts\"][hex_code][\"identifiers\"][k].append({\n",
    "                \"affixes\": [affix] if affix else [],\n",
    "                \"arity\": 0,\n",
    "                \"description\": value\n",
    "            })\n",
    "    else:\n",
    "        if hex_code not in mc_dict_original[\"concepts\"]:\n",
    "            mc_dict_original[\"concepts\"][hex_code] = {\n",
    "                \"_surface\": {\n",
    "                    \"text\": base_key,\n",
    "                    \"unicode_name\": base_key if len(base_key) != 1 else unicodedata.name(base_key)\n",
    "                },\n",
    "                \"identifiers\": {\n",
    "                    'default': []\n",
    "                }\n",
    "            }\n",
    "\n",
    "        for value in values:\n",
    "            mc_dict_original[\"concepts\"][hex_code][\"identifiers\"][\"default\"].append({\n",
    "                \"affixes\": [affix] if affix else [],\n",
    "                \"arity\": 0,\n",
    "                \"description\": value\n",
    "            })\n",
    "\n",
    "\n",
    "# Convert new dictionary to a sorted dictionary\n",
    "sorted_dict = dict(sorted(mc_dict_original[\"concepts\"].items(), key=lambda x: (len(x[0]), x[0])))\n",
    "mc_dict_original[\"concepts\"] = sorted_dict\n",
    "\n",
    "# Convert new dictionary to JSON\n",
    "json_str = json.dumps(mc_dict_original, indent=4, ensure_ascii=False)\n",
    "\n",
    "#print(json_str)\n",
    "\n",
    "with open(f'{file_code}-{model_name}_mcdict.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(mc_dict_original, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a79ec2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_tags(element):\n",
    "    if isinstance(element, NavigableString):\n",
    "        return element\n",
    "    if element.name == 'mi':\n",
    "        return str(element)\n",
    "    return ''.join(get_text_from_tags(child) for child in element.children)\n",
    "\n",
    "def parse_html(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as html_file:\n",
    "        soup = BeautifulSoup(html_file, 'html.parser')\n",
    "\n",
    "    texts = get_text_from_tags(soup)\n",
    "    return texts\n",
    "\n",
    "def find_mi_strings(text):\n",
    "    pattern = r'(<mi.*?</mi>)'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return matches\n",
    "\n",
    "# call the function with your HTML file path\n",
    "page = parse_html(f'{file_code}.html')\n",
    "matches = find_mi_strings(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64a0cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dict = mc_dict_original\n",
    "with open(f'{file_code}_anno.json', encoding='utf-8') as fp:\n",
    "    parsed_annotation = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "163356dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index_from_char_index(message, key, char_index):\n",
    "    i = 0\n",
    "    index = -1\n",
    "    for word in message:\n",
    "        if key in word:\n",
    "            index = i\n",
    "        i += 1\n",
    "    return index\n",
    "\n",
    "def expand_string_to_tokens(message, index, num_tokens_right=25, num_tokens_left=75):\n",
    "    words = message.split()  # Split the message into words\n",
    "\n",
    "    # Start at the index where the center word is\n",
    "    left_index = right_index = index\n",
    "\n",
    "    tokens_counter_right = num_tokens_from_messages(words[right_index])\n",
    "    tokens_counter_left = num_tokens_from_messages(words[left_index])\n",
    "\n",
    "    # Expand to the left from the center index until you reach num_tokens_left\n",
    "    while tokens_counter_left < num_tokens_left and left_index > 0:\n",
    "        left_index -= 1\n",
    "        tokens_counter_left += num_tokens_from_messages(words[left_index])\n",
    "\n",
    "    # Expand to the right from the center index until you reach num_tokens_right\n",
    "    while tokens_counter_right < num_tokens_right and right_index < len(words) - 1:\n",
    "        right_index += 1\n",
    "        tokens_counter_right += num_tokens_from_messages(words[right_index])\n",
    "\n",
    "    # Combine the words back into a string and return\n",
    "    return ' '.join(words[left_index:right_index + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01b6b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_text(text, replacement, exception):\n",
    "    # Find all matches\n",
    "    matches = re.findall(r'<mi(.*?)</mi>', text)\n",
    "    \n",
    "    for match in matches:\n",
    "        original_string = f'<mi{match}</mi>'\n",
    "        \n",
    "        # Skip exception\n",
    "        if original_string == exception:\n",
    "            continue\n",
    "        \n",
    "        # Replace match\n",
    "        replaced_string = re.sub(r'<.*?>(.*?)</.*?>', r'\\1', original_string)\n",
    "        text = text.replace(original_string, replaced_string)\n",
    "\n",
    "    return text\n",
    "\n",
    "def get_context(match):\n",
    "    match_len = len(match)\n",
    "    new_page = replace_text(page, '', match)\n",
    "    char_index = new_page.index(match) + int(match_len/2)\n",
    "    word_index = get_word_index_from_char_index(new_page, char_index)\n",
    "    section = expand_string_to_tokens(new_page, word_index)\n",
    "    section = re.sub(r'<.*?>(.*?)</.*?>', r'<<\\1>>', section)\n",
    "    return match, section\n",
    "\n",
    "# Function to create a hex code (a binary representation of the key)\n",
    "def get_hex_code(key):\n",
    "    return key.encode('utf-8').hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7706ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trailing_tags(s):\n",
    "    parts = re.split('(<mi)', s)\n",
    "    for i in range(1, len(parts), 2):\n",
    "        if '>' not in parts[i + 1]:\n",
    "            parts[i] = ''\n",
    "            parts[i + 1] = ''\n",
    "    return ''.join(parts)\n",
    "\n",
    "def get_definition_of_id(dict_id, identifier):\n",
    "    \n",
    "    try:\n",
    "        hex_code = get_hex_code(identifier)\n",
    "        index = parsed_annotation['mi_anno'][dict_id]['concept_id']\n",
    "        key = list(parsed_dict['concepts'][hex_code]['identifiers'].keys())[0]\n",
    "        return f\"({parsed_dict['concepts'][hex_code]['identifiers'][key][index]['description']})\"\n",
    "    except Exception as e:\n",
    "        return \"\"\n",
    "\n",
    "def get_context(match):\n",
    "    key_word = page.index(match) + len(match)\n",
    "    last_index = min(len(page), key_word + 500)\n",
    "    first_index = max(0, key_word - 3000)\n",
    "    context_window = page[first_index:last_index]\n",
    "    \n",
    "    reg_matches = re.findall(r'<mi(.*?)</mi>', context_window)\n",
    "    \n",
    "    identifier = None\n",
    "    \n",
    "    for reg_match in reg_matches:\n",
    "        original_string = f'<mi{reg_match}</mi>'\n",
    "        soup = BeautifulSoup(original_string, 'html.parser')\n",
    "        \n",
    "        \n",
    "        tags = soup.find_all('mi')\n",
    "        \n",
    "        if original_string == match:\n",
    "            identifier = tags[0].text\n",
    "            continue\n",
    "\n",
    "        context_window = context_window.replace(original_string,\n",
    "                                                f\"{tags[0].text}{get_definition_of_id(tags[0].get('id'), tags[0].text)}\")\n",
    "    \n",
    "    context_window = re.sub(r'<mi.*?>(.*?)<\\/mi>', r'<<\\1>>', context_window)\n",
    "    \n",
    "    context_window = remove_trailing_tags(context_window)\n",
    "    context_window = re.sub(r'^(?!.*<mi.*).*<\\/mi>', '', context_window, flags=re.DOTALL)\n",
    "        \n",
    "    index = 0\n",
    "    for word in context_window.split():\n",
    "        if f\"<<{identifier}>>\" in word:\n",
    "            word_index = index\n",
    "        index += 1\n",
    "    \n",
    "    if word_index == -1:\n",
    "        return context_window\n",
    "    else:\n",
    "        context_window = expand_string_to_tokens(context_window, word_index)\n",
    "    return context_window\n",
    "\n",
    "#print(get_context('<mi id=\"S1.p2.1.m1.1.1.3\" xref=\"S1.p2.1.m1.1.1.3.cmml\">φ</mi>'))\n",
    "#get_context('<mi id=\"S1.p2.1.m1.1.1.2\" xref=\"S1.p2.1.m1.1.1.2.cmml\">𝖤</mi>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62ec5036-7177-46d0-9728-571edb9f6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_anno(prompt):\n",
    "    return f'''### SYSTEM:\\n{prompt[0]['content']}\\n\\n\n",
    "### USER:\\n{prompt[1]['content']}\\n\\n\n",
    "### ASSISTANT:\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f57696ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 486: Key does not exist in the dictionary of concepts  \n",
      "Iteration 2 of 486: Key does not exist in the dictionary of concepts  \n",
      "Iteration 3 of 486: Key does not exist in the dictionary of concepts  \n",
      "Iteration 4 of 486: 0\n",
      "Iteration 5 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "6 318\n",
      "2\n",
      "Iteration 6 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "12 620\n",
      "0\n",
      "Iteration 7 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "18 933\n",
      "2\n",
      "Iteration 8 of 486: 0\n",
      "Iteration 9 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "24 1250\n",
      "2\n",
      "Iteration 10 of 486: 0\n",
      "Iteration 11 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "30 1571\n",
      "2\n",
      "Iteration 12 of 486: 0\n",
      "Iteration 13 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "36 1886\n",
      "2\n",
      "Iteration 14 of 486: 0\n",
      "Iteration 15 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "42 2201\n",
      "2\n",
      "Iteration 16 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "48 2517\n",
      "2\n",
      "Iteration 17 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "54 2821\n",
      "0\n",
      "Iteration 18 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "60 3135\n",
      "2\n",
      "Iteration 19 of 486: 0\n",
      "Iteration 20 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "66 3448\n",
      "2\n",
      "Iteration 21 of 486: 0\n",
      "Iteration 22 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "72 3764\n",
      "2\n",
      "Iteration 23 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "78 4059\n",
      "0\n",
      "Iteration 24 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "84 4341\n",
      "0\n",
      "Iteration 25 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "90 4661\n",
      "2\n",
      "Iteration 26 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "96 4984\n",
      "1\n",
      "Iteration 27 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "102 5264\n",
      "0\n",
      "Iteration 28 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "108 5546\n",
      "1\n",
      "Iteration 29 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "114 5870\n",
      "2\n",
      "Iteration 30 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "120 6147\n",
      "1\n",
      "Iteration 31 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "126 6410\n",
      "0\n",
      "Iteration 32 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "132 6717\n",
      "2\n",
      "Iteration 33 of 486: None\n",
      "Iteration 34 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "138 6992\n",
      "1\n",
      "Iteration 35 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "144 7269\n",
      "0\n",
      "Iteration 36 of 486: None\n",
      "Iteration 37 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "150 7544\n",
      "0\n",
      "Iteration 38 of 486: None\n",
      "Iteration 39 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "156 7819\n",
      "0\n",
      "Iteration 40 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "162 8103\n",
      "0\n",
      "Iteration 41 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "168 8429\n",
      "2\n",
      "Iteration 42 of 486: 0\n",
      "Iteration 43 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "174 8717\n",
      "0\n",
      "Iteration 44 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "180 9038\n",
      "2\n",
      "Iteration 45 of 486: None\n",
      "Iteration 46 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "186 9335\n",
      "0\n",
      "Iteration 47 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "192 9623\n",
      "1\n",
      "Iteration 48 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "198 9896\n",
      "0\n",
      "Iteration 49 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "204 10214\n",
      "2\n",
      "Iteration 50 of 486: None\n",
      "Iteration 51 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "210 10484\n",
      "0\n",
      "Iteration 52 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "216 10802\n",
      "2\n",
      "Iteration 53 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "222 11094\n",
      "1\n",
      "Iteration 54 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "228 11368\n",
      "0\n",
      "Iteration 55 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "234 11692\n",
      "2\n",
      "Iteration 56 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "240 11999\n",
      "1\n",
      "Iteration 57 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "246 12324\n",
      "2\n",
      "Iteration 58 of 486: 0\n",
      "Iteration 59 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "252 12615\n",
      "0\n",
      "Iteration 60 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "258 12941\n",
      "2\n",
      "Iteration 61 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "264 13247\n",
      "1\n",
      "Iteration 62 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "270 13533\n",
      "0\n",
      "Iteration 63 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "276 13862\n",
      "2\n",
      "Iteration 64 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "282 14153\n",
      "1\n",
      "Iteration 65 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "288 14424\n",
      "0\n",
      "Iteration 66 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "294 14739\n",
      "2\n",
      "Iteration 67 of 486: None\n",
      "Iteration 68 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "300 15016\n",
      "0\n",
      "Iteration 69 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "306 15289\n",
      "0\n",
      "Iteration 70 of 486: None\n",
      "Iteration 71 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "312 15564\n",
      "0\n",
      "Iteration 72 of 486: None\n",
      "Iteration 73 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "318 15837\n",
      "0\n",
      "Iteration 74 of 486: 0\n",
      "Iteration 75 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "324 16150\n",
      "0\n",
      "Iteration 76 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "330 16473\n",
      "1\n",
      "Iteration 77 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "336 16775\n",
      "1\n",
      "Iteration 78 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "342 17070\n",
      "0\n",
      "Iteration 79 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "348 17386\n",
      "1\n",
      "Iteration 80 of 486: None\n",
      "Iteration 81 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "354 17665\n",
      "1\n",
      "Iteration 82 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "360 17947\n",
      "0\n",
      "Iteration 83 of 486: None\n",
      "Iteration 84 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "366 18229\n",
      "0\n",
      "Iteration 85 of 486: None\n",
      "Iteration 86 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "372 18511\n",
      "0\n",
      "Iteration 87 of 486: None\n",
      "Iteration 88 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "378 18786\n",
      "0\n",
      "Iteration 89 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "384 19108\n",
      "1\n",
      "Iteration 90 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "390 19405\n",
      "1\n",
      "Iteration 91 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "396 19681\n",
      "0\n",
      "Iteration 92 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "402 20004\n",
      "1\n",
      "Iteration 93 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "408 20316\n",
      "2\n",
      "Iteration 94 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "414 20647\n",
      "1\n",
      "Iteration 95 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "420 20988\n",
      "2\n",
      "Iteration 96 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "426 21300\n",
      "0\n",
      "Iteration 97 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "432 21622\n",
      "1\n",
      "Iteration 98 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "438 21952\n",
      "2\n",
      "Iteration 99 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "444 22243\n",
      "0\n",
      "Iteration 100 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "450 22581\n",
      "1\n",
      "Iteration 101 of 486: Key does not exist in the dictionary of concepts ... 2e2e2e\n",
      "Iteration 102 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "456 22907\n",
      "2\n",
      "Iteration 103 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "462 23198\n",
      "0\n",
      "Iteration 104 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "468 23493\n",
      "0\n",
      "Iteration 105 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "474 23787\n",
      "0\n",
      "Iteration 106 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "480 24124\n",
      "1\n",
      "Iteration 107 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "486 24418\n",
      "0\n",
      "Iteration 108 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "492 24754\n",
      "2\n",
      "Iteration 109 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "498 25051\n",
      "0\n",
      "Iteration 110 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "504 25343\n",
      "0\n",
      "Iteration 111 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "510 25676\n",
      "1\n",
      "Iteration 112 of 486: 0\n",
      "Iteration 113 of 486: None\n",
      "Iteration 114 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "516 25991\n",
      "1\n",
      "Iteration 115 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "522 26318\n",
      "1\n",
      "Iteration 116 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "528 26619\n",
      "1\n",
      "Iteration 117 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "534 26934\n",
      "1\n",
      "Iteration 118 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "540 27219\n",
      "1\n",
      "Iteration 119 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "546 27489\n",
      "1\n",
      "Iteration 120 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "552 27802\n",
      "2\n",
      "Iteration 121 of 486: ASSISTANT:\n",
      " 3</s>\n",
      "558 28124\n",
      "3\n",
      "Iteration 122 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "564 28399\n",
      "1\n",
      "Iteration 123 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "570 28674\n",
      "1\n",
      "Iteration 124 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "576 28995\n",
      "1\n",
      "Iteration 125 of 486: 0\n",
      "Iteration 126 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "582 29269\n",
      "0\n",
      "Iteration 127 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "588 29546\n",
      "1\n",
      "Iteration 128 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "594 29867\n",
      "1\n",
      "Iteration 129 of 486: 0\n",
      "Iteration 130 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "600 30145\n",
      "0\n",
      "Iteration 131 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "606 30429\n",
      "1\n",
      "Iteration 132 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "612 30751\n",
      "1\n",
      "Iteration 133 of 486: 0\n",
      "Iteration 134 of 486: 0\n",
      "Iteration 135 of 486: 0\n",
      "Iteration 136 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "618 31065\n",
      "1\n",
      "Iteration 137 of 486: None\n",
      "Iteration 138 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "624 31395\n",
      "1\n",
      "Iteration 139 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "630 31723\n",
      "2\n",
      "Iteration 140 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "636 32030\n",
      "0\n",
      "Iteration 141 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "642 32342\n",
      "1\n",
      "Iteration 142 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "648 32685\n",
      "1\n",
      "Iteration 143 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "654 33011\n",
      "1\n",
      "Iteration 144 of 486: None\n",
      "Iteration 145 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "660 33349\n",
      "1\n",
      "Iteration 146 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "666 33709\n",
      "1\n",
      "Iteration 147 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "672 33995\n",
      "1\n",
      "Iteration 148 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "678 34278\n",
      "1\n",
      "Iteration 149 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "684 34559\n",
      "0\n",
      "Iteration 150 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "690 34891\n",
      "0\n",
      "Iteration 151 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "696 35182\n",
      "0\n",
      "Iteration 152 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "702 35475\n",
      "1\n",
      "Iteration 153 of 486: ASSISTANT:\n",
      " 3</s>\n",
      "708 35786\n",
      "3\n",
      "Iteration 154 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "714 36057\n",
      "0\n",
      "Iteration 155 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "720 36333\n",
      "1\n",
      "Iteration 156 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "726 36641\n",
      "1\n",
      "Iteration 157 of 486: 0\n",
      "Iteration 158 of 486: ASSISTANT:\n",
      " 3</s>\n",
      "732 36957\n",
      "3\n",
      "Iteration 159 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "738 37234\n",
      "0\n",
      "Iteration 160 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "744 37515\n",
      "1\n",
      "Iteration 161 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "750 37848\n",
      "1\n",
      "Iteration 162 of 486: 0\n",
      "Iteration 163 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "756 38130\n",
      "0\n",
      "Iteration 164 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "762 38416\n",
      "1\n",
      "Iteration 165 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "768 38754\n",
      "1\n",
      "Iteration 166 of 486: 0\n",
      "Iteration 167 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "774 39037\n",
      "1\n",
      "Iteration 168 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "780 39302\n",
      "1\n",
      "Iteration 169 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "786 39612\n",
      "1\n",
      "Iteration 170 of 486: 0\n",
      "Iteration 171 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "792 39885\n",
      "1\n",
      "Iteration 172 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "798 40201\n",
      "1\n",
      "Iteration 173 of 486: 0\n",
      "Iteration 174 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "804 40488\n",
      "1\n",
      "Iteration 175 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "810 40816\n",
      "1\n",
      "Iteration 176 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "816 41119\n",
      "1\n",
      "Iteration 177 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "822 41415\n",
      "1\n",
      "Iteration 178 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "828 41759\n",
      "1\n",
      "Iteration 179 of 486: 0\n",
      "Iteration 180 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "834 42069\n",
      "1\n",
      "Iteration 181 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "840 42396\n",
      "1\n",
      "Iteration 182 of 486: ASSISTANT:\n",
      " 3</s>\n",
      "846 42732\n",
      "3\n",
      "Iteration 183 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "852 43027\n",
      "1\n",
      "Iteration 184 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "858 43347\n",
      "1\n",
      "Iteration 185 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "864 43672\n",
      "2\n",
      "Iteration 186 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "870 43990\n",
      "1\n",
      "Iteration 187 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "876 44311\n",
      "1\n",
      "Iteration 188 of 486: Key does not exist in the dictionary of concepts ... 2e2e2e\n",
      "Iteration 189 of 486: ASSISTANT:\n",
      " 3</s>\n",
      "882 44636\n",
      "3\n",
      "Iteration 190 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "888 44925\n",
      "1\n",
      "Iteration 191 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "894 45218\n",
      "0\n",
      "Iteration 192 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "900 45503\n",
      "1\n",
      "Iteration 193 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "906 45830\n",
      "1\n",
      "Iteration 194 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "912 46144\n",
      "2\n",
      "Iteration 195 of 486: 0\n",
      "Iteration 196 of 486: 0\n",
      "Iteration 197 of 486: 0\n",
      "Iteration 198 of 486: 0\n",
      "Iteration 199 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "918 46468\n",
      "0\n",
      "Iteration 200 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "924 46817\n",
      "2\n",
      "Iteration 201 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "930 47134\n",
      "0\n",
      "Iteration 202 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "936 47452\n",
      "0\n",
      "Iteration 203 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "942 47778\n",
      "0\n",
      "Iteration 204 of 486: None\n",
      "Iteration 205 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "948 48066\n",
      "0\n",
      "Iteration 206 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "954 48375\n",
      "1\n",
      "Iteration 207 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "960 48658\n",
      "0\n",
      "Iteration 208 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "966 48985\n",
      "1\n",
      "Iteration 209 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "972 49299\n",
      "2\n",
      "Iteration 210 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "978 49627\n",
      "1\n",
      "Iteration 211 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "984 49908\n",
      "1\n",
      "Iteration 212 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "990 50200\n",
      "0\n",
      "Iteration 213 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "996 50492\n",
      "0\n",
      "Iteration 214 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1002 50794\n",
      "2\n",
      "Iteration 215 of 486: 0\n",
      "Iteration 216 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1008 51072\n",
      "0\n",
      "Iteration 217 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1014 51347\n",
      "0\n",
      "Iteration 218 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1020 51629\n",
      "0\n",
      "Iteration 219 of 486: 0\n",
      "Iteration 220 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1026 51929\n",
      "1\n",
      "Iteration 221 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1032 52212\n",
      "0\n",
      "Iteration 222 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1038 52539\n",
      "1\n",
      "Iteration 223 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1044 52841\n",
      "1\n",
      "Iteration 224 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1050 53133\n",
      "0\n",
      "Iteration 225 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1056 53468\n",
      "1\n",
      "Iteration 226 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1062 53770\n",
      "1\n",
      "Iteration 227 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1068 54046\n",
      "0\n",
      "Iteration 228 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1074 54361\n",
      "1\n",
      "Iteration 229 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1080 54651\n",
      "1\n",
      "Iteration 230 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1086 54923\n",
      "0\n",
      "Iteration 231 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1092 55241\n",
      "1\n",
      "Iteration 232 of 486: 0\n",
      "Iteration 233 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1098 55517\n",
      "0\n",
      "Iteration 234 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1104 55837\n",
      "1\n",
      "Iteration 235 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1110 56131\n",
      "1\n",
      "Iteration 236 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1116 56419\n",
      "0\n",
      "Iteration 237 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1122 56750\n",
      "1\n",
      "Iteration 238 of 486: 0\n",
      "Iteration 239 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1128 57042\n",
      "0\n",
      "Iteration 240 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1134 57376\n",
      "1\n",
      "Iteration 241 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1140 57680\n",
      "1\n",
      "Iteration 242 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1146 58064\n",
      "0\n",
      "Iteration 243 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1152 58416\n",
      "1\n",
      "Iteration 244 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1158 58807\n",
      "0\n",
      "Iteration 245 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1164 59090\n",
      "0\n",
      "Iteration 246 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1170 59415\n",
      "1\n",
      "Iteration 247 of 486: 0\n",
      "Iteration 248 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1176 59751\n",
      "0\n",
      "Iteration 249 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1182 60098\n",
      "1\n",
      "Iteration 250 of 486: None\n",
      "Iteration 251 of 486: 0\n",
      "Iteration 252 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1188 60380\n",
      "0\n",
      "Iteration 253 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1194 60708\n",
      "1\n",
      "Iteration 254 of 486: 0\n",
      "Iteration 255 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1200 60994\n",
      "0\n",
      "Iteration 256 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1206 61325\n",
      "1\n",
      "Iteration 257 of 486: None\n",
      "Iteration 258 of 486: 0\n",
      "Iteration 259 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1212 61613\n",
      "0\n",
      "Iteration 260 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1218 61945\n",
      "1\n",
      "Iteration 261 of 486: 0\n",
      "Iteration 262 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1224 62225\n",
      "0\n",
      "Iteration 263 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1230 62549\n",
      "1\n",
      "Iteration 264 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1236 62860\n",
      "1\n",
      "Iteration 265 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1242 63143\n",
      "0\n",
      "Iteration 266 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1248 63425\n",
      "0\n",
      "Iteration 267 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1254 63743\n",
      "1\n",
      "Iteration 268 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1260 64065\n",
      "2\n",
      "Iteration 269 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1266 64343\n",
      "0\n",
      "Iteration 270 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1272 64625\n",
      "0\n",
      "Iteration 271 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1278 64954\n",
      "1\n",
      "Iteration 272 of 486: 0\n",
      "Iteration 273 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1284 65296\n",
      "2\n",
      "Iteration 274 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1290 65577\n",
      "0\n",
      "Iteration 275 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1296 65861\n",
      "0\n",
      "Iteration 276 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1302 66188\n",
      "1\n",
      "Iteration 277 of 486: 0\n",
      "Iteration 278 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1308 66473\n",
      "1\n",
      "Iteration 279 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1314 66769\n",
      "0\n",
      "Iteration 280 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1320 67070\n",
      "0\n",
      "Iteration 281 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1326 67417\n",
      "1\n",
      "Iteration 282 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1332 67746\n",
      "2\n",
      "Iteration 283 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1338 68041\n",
      "0\n",
      "Iteration 284 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1344 68330\n",
      "0\n",
      "Iteration 285 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1350 68659\n",
      "1\n",
      "Iteration 286 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1356 68965\n",
      "0\n",
      "Iteration 287 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1362 69253\n",
      "0\n",
      "Iteration 288 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1368 69584\n",
      "1\n",
      "Iteration 289 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1374 69876\n",
      "0\n",
      "Iteration 290 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1380 70204\n",
      "1\n",
      "Iteration 291 of 486: 0\n",
      "Iteration 292 of 486: 0\n",
      "Iteration 293 of 486: 0\n",
      "Iteration 294 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1386 70480\n",
      "1\n",
      "Iteration 295 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1392 70797\n",
      "1\n",
      "Iteration 296 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1398 71117\n",
      "1\n",
      "Iteration 297 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1404 71392\n",
      "1\n",
      "Iteration 298 of 486: 0\n",
      "Iteration 299 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1410 71664\n",
      "1\n",
      "Iteration 300 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1416 71977\n",
      "1\n",
      "Iteration 301 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1422 72292\n",
      "2\n",
      "Iteration 302 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1428 72566\n",
      "0\n",
      "Iteration 303 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1434 73005\n",
      "2\n",
      "Iteration 304 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1440 73280\n",
      "0\n",
      "Iteration 305 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1446 73596\n",
      "2\n",
      "Iteration 306 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1452 73879\n",
      "0\n",
      "Iteration 307 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1458 74207\n",
      "0\n",
      "Iteration 308 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1464 74487\n",
      "0\n",
      "Iteration 309 of 486: 0\n",
      "Iteration 310 of 486: None\n",
      "Iteration 311 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1470 74792\n",
      "1\n",
      "Iteration 312 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1476 75074\n",
      "0\n",
      "Iteration 313 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1482 75388\n",
      "1\n",
      "Iteration 314 of 486: 0\n",
      "Iteration 315 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1488 75681\n",
      "0\n",
      "Iteration 316 of 486: 0\n",
      "Iteration 317 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1494 75967\n",
      "1\n",
      "Iteration 318 of 486: 0\n",
      "Iteration 319 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1500 76299\n",
      "0\n",
      "Iteration 320 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1506 76575\n",
      "0\n",
      "Iteration 321 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1512 76851\n",
      "0\n",
      "Iteration 322 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1518 77136\n",
      "1\n",
      "Iteration 323 of 486: 0\n",
      "Iteration 324 of 486: 0\n",
      "Iteration 325 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1524 77587\n",
      "2\n",
      "Iteration 326 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1530 77872\n",
      "0\n",
      "Iteration 327 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1536 78168\n",
      "1\n",
      "Iteration 328 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1542 78620\n",
      "2\n",
      "Iteration 329 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1548 78909\n",
      "0\n",
      "Iteration 330 of 486: 0\n",
      "Iteration 331 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1554 79208\n",
      "0\n",
      "Iteration 332 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1560 79535\n",
      "1\n",
      "Iteration 333 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1566 79845\n",
      "1\n",
      "Iteration 334 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1572 80151\n",
      "0\n",
      "Iteration 335 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1578 80464\n",
      "1\n",
      "Iteration 336 of 486: 0\n",
      "Iteration 337 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1584 80799\n",
      "0\n",
      "Iteration 338 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1590 81140\n",
      "2\n",
      "Iteration 339 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1596 81480\n",
      "2\n",
      "Iteration 340 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1602 81845\n",
      "1\n",
      "Iteration 341 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1608 82129\n",
      "1\n",
      "Iteration 342 of 486: 0\n",
      "Iteration 343 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1614 82415\n",
      "0\n",
      "Iteration 344 of 486: 0\n",
      "Iteration 345 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1620 82736\n",
      "1\n",
      "Iteration 346 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1626 83175\n",
      "2\n",
      "Iteration 347 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1632 83452\n",
      "1\n",
      "Iteration 348 of 486: None\n",
      "Iteration 349 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1638 83732\n",
      "1\n",
      "Iteration 350 of 486: None\n",
      "Iteration 351 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1644 84016\n",
      "1\n",
      "Iteration 352 of 486: Key does not exist in the dictionary of concepts ... 2e2e2e\n",
      "Iteration 353 of 486: None\n",
      "Iteration 354 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1650 84318\n",
      "2\n",
      "Iteration 355 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1656 84601\n",
      "1\n",
      "Iteration 356 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1662 84886\n",
      "1\n",
      "Iteration 357 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1668 85188\n",
      "0\n",
      "Iteration 358 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1674 85648\n",
      "2\n",
      "Iteration 359 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1680 85941\n",
      "0\n",
      "Iteration 360 of 486: 0\n",
      "Iteration 361 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1686 86408\n",
      "2\n",
      "Iteration 362 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1692 86723\n",
      "1\n",
      "Iteration 363 of 486: None\n",
      "Iteration 364 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1698 87041\n",
      "1\n",
      "Iteration 365 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1704 87391\n",
      "2\n",
      "Iteration 366 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1710 87724\n",
      "1\n",
      "Iteration 367 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1716 88067\n",
      "1\n",
      "Iteration 368 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1722 88361\n",
      "0\n",
      "Iteration 369 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1728 88659\n",
      "0\n",
      "Iteration 370 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1734 88953\n",
      "1\n",
      "Iteration 371 of 486: 0\n",
      "Iteration 372 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1740 89255\n",
      "1\n",
      "Iteration 373 of 486: 0\n",
      "Iteration 374 of 486: None\n",
      "Iteration 375 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1746 89543\n",
      "0\n",
      "Iteration 376 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1752 89864\n",
      "1\n",
      "Iteration 377 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1758 90169\n",
      "1\n",
      "Iteration 378 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1764 90470\n",
      "0\n",
      "Iteration 379 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1770 90779\n",
      "0\n",
      "Iteration 380 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1776 91127\n",
      "1\n",
      "Iteration 381 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1782 91426\n",
      "0\n",
      "Iteration 382 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1788 91723\n",
      "0\n",
      "Iteration 383 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1794 92029\n",
      "1\n",
      "Iteration 384 of 486: 0\n",
      "Iteration 385 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1800 92335\n",
      "1\n",
      "Iteration 386 of 486: 0\n",
      "Iteration 387 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1806 92670\n",
      "1\n",
      "Iteration 388 of 486: 0\n",
      "Iteration 389 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1812 92958\n",
      "0\n",
      "Iteration 390 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1818 93400\n",
      "2\n",
      "Iteration 391 of 486: 0\n",
      "Iteration 392 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1824 93843\n",
      "2\n",
      "Iteration 393 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1830 94131\n",
      "1\n",
      "Iteration 394 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1836 94444\n",
      "1\n",
      "Iteration 395 of 486: 0\n",
      "Iteration 396 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1842 94736\n",
      "0\n",
      "Iteration 397 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1848 95051\n",
      "1\n",
      "Iteration 398 of 486: 0\n",
      "Iteration 399 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1854 95355\n",
      "0\n",
      "Iteration 400 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1860 95817\n",
      "2\n",
      "Iteration 401 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1866 96112\n",
      "0\n",
      "Iteration 402 of 486: 0\n",
      "Iteration 403 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1872 96577\n",
      "2\n",
      "Iteration 404 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1878 96898\n",
      "1\n",
      "Iteration 405 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1884 97221\n",
      "1\n",
      "Iteration 406 of 486: 0\n",
      "Iteration 407 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1890 97524\n",
      "1\n",
      "Iteration 408 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1896 97984\n",
      "2\n",
      "Iteration 409 of 486: 0\n",
      "Iteration 410 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1902 98437\n",
      "2\n",
      "Iteration 411 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1908 98745\n",
      "1\n",
      "Iteration 412 of 486: 0\n",
      "Iteration 413 of 486: ASSISTANT:\n",
      " 4</s>\n",
      "1914 99183\n",
      "4\n",
      "Iteration 414 of 486: 0\n",
      "Iteration 415 of 486: ASSISTANT:\n",
      " 4</s>\n",
      "1920 99625\n",
      "4\n",
      "Iteration 416 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1926 99911\n",
      "1\n",
      "Iteration 417 of 486: 0\n",
      "Iteration 418 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1932 100213\n",
      "0\n",
      "Iteration 419 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1938 100674\n",
      "2\n",
      "Iteration 420 of 486: 0\n",
      "Iteration 421 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1944 101127\n",
      "2\n",
      "Iteration 422 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1950 101419\n",
      "1\n",
      "Iteration 423 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1956 101736\n",
      "0\n",
      "Iteration 424 of 486: ASSISTANT:\n",
      " 4</s>\n",
      "1962 102196\n",
      "4\n",
      "Iteration 425 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1968 102489\n",
      "1\n",
      "Iteration 426 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1974 102947\n",
      "2\n",
      "Iteration 427 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "1980 103238\n",
      "1\n",
      "Iteration 428 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "1986 103542\n",
      "0\n",
      "Iteration 429 of 486: ASSISTANT:\n",
      " 4</s>\n",
      "1992 104006\n",
      "4\n",
      "Iteration 430 of 486: 0\n",
      "Iteration 431 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "1998 104462\n",
      "2\n",
      "Iteration 432 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2004 104772\n",
      "1\n",
      "Iteration 433 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2010 105063\n",
      "1\n",
      "Iteration 434 of 486: 0\n",
      "Iteration 435 of 486: 0\n",
      "Iteration 436 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2016 105429\n",
      "2\n",
      "Iteration 437 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2022 105793\n",
      "2\n",
      "Iteration 438 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2028 106111\n",
      "1\n",
      "Iteration 439 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2034 106507\n",
      "1\n",
      "Iteration 440 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2040 106799\n",
      "0\n",
      "Iteration 441 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2046 107138\n",
      "1\n",
      "Iteration 442 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2052 107441\n",
      "0\n",
      "Iteration 443 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2058 107751\n",
      "0\n",
      "Iteration 444 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2064 108067\n",
      "1\n",
      "Iteration 445 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2070 108432\n",
      "1\n",
      "Iteration 446 of 486: 0\n",
      "Iteration 447 of 486: ASSISTANT:\n",
      " 6</s>\n",
      "2076 108882\n",
      "6\n",
      "Iteration 448 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2082 109223\n",
      "1\n",
      "Iteration 449 of 486: ASSISTANT:\n",
      " 7</s>\n",
      "2088 109676\n",
      "7\n",
      "Iteration 450 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2094 109967\n",
      "1\n",
      "Iteration 451 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2100 110292\n",
      "1\n",
      "Iteration 452 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2106 110687\n",
      "0\n",
      "Iteration 453 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2112 110990\n",
      "0\n",
      "Iteration 454 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2118 111334\n",
      "1\n",
      "Iteration 455 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2124 111637\n",
      "0\n",
      "Iteration 456 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2130 111912\n",
      "0\n",
      "Iteration 457 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2136 112221\n",
      "0\n",
      "Iteration 458 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2142 112498\n",
      "0\n",
      "Iteration 459 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2148 112778\n",
      "0\n",
      "Iteration 460 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2154 113057\n",
      "0\n",
      "Iteration 461 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2160 113362\n",
      "1\n",
      "Iteration 462 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2166 113681\n",
      "2\n",
      "Iteration 463 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2172 113983\n",
      "1\n",
      "Iteration 464 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2178 114297\n",
      "2\n",
      "Iteration 465 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2184 114604\n",
      "2\n",
      "Iteration 466 of 486: 0\n",
      "Iteration 467 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2190 114958\n",
      "2\n",
      "Iteration 468 of 486: 0\n",
      "Iteration 469 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2196 115309\n",
      "2\n",
      "Iteration 470 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2202 115701\n",
      "0\n",
      "Iteration 471 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2208 116011\n",
      "2\n",
      "Iteration 472 of 486: 0\n",
      "Iteration 473 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2214 116366\n",
      "2\n",
      "Iteration 474 of 486: 0\n",
      "Iteration 475 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2220 116718\n",
      "2\n",
      "Iteration 476 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2226 117112\n",
      "0\n",
      "Iteration 477 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2232 117426\n",
      "2\n",
      "Iteration 478 of 486: 0\n",
      "Iteration 479 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2238 117732\n",
      "2\n",
      "Iteration 480 of 486: ASSISTANT:\n",
      " 0</s>\n",
      "2244 118118\n",
      "0\n",
      "Iteration 481 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2250 118451\n",
      "2\n",
      "Iteration 482 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2256 118734\n",
      "1\n",
      "Iteration 483 of 486: 0\n",
      "Iteration 484 of 486: ASSISTANT:\n",
      " 2</s>\n",
      "2262 119069\n",
      "2\n",
      "Iteration 485 of 486: ASSISTANT:\n",
      " 1</s>\n",
      "2268 119355\n",
      "1\n",
      "Iteration 486 of 486: 0\n",
      "Annotation completed\n",
      "Time taken: 0:10:52.778593\n",
      "Total time taken: 0:10:52.778557\n",
      "121623 2268 119355\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "actual_total_tokens = 0\n",
    "completion_tokens = 0\n",
    "prompt_tokens = 0\n",
    "no_tags = 0\n",
    "no_keys = 0\n",
    "no_anno = 0\n",
    "i = 1\n",
    "for match in matches:\n",
    "    print(f\"Iteration {i} of {len(matches)}: \", end='')\n",
    "    i += 1\n",
    "    context = get_context(match)\n",
    "    match_variable = re.sub(r'<.*?>(.*?)</.*?>', r'\\1', match)\n",
    "    context_index = context.index(f\"<<{match_variable}>>\") + len(match_variable)\n",
    "    possible_affix = str(context[context_index+4:context_index+5]).replace(\"′\", \"'\")\n",
    "    soup = BeautifulSoup(match, 'html.parser')\n",
    "    mi_tag = soup.find('mi')\n",
    "    if mi_tag is not None and 'id' in mi_tag.attrs:\n",
    "        anno_id = mi_tag['id']\n",
    "    else:\n",
    "        print('TAG NOT FOUND', match)\n",
    "        no_tags += 1\n",
    "        continue\n",
    "    \n",
    "    hex_code = get_hex_code(match_variable)\n",
    "    if hex_code not in parsed_dict['concepts']:\n",
    "        match_variable = f\"{unidecode(match_variable)}\"\n",
    "        hex_code = get_hex_code(match_variable)\n",
    "        if hex_code not in parsed_dict['concepts']:\n",
    "            print(\"Key does not exist in the dictionary of concepts\", match_variable, hex_code)\n",
    "            no_keys += 1\n",
    "            continue\n",
    "    \n",
    "    if anno_id not in parsed_annotation['mi_anno']:\n",
    "        print(\"Annotation ID does not exist in annotation.json\", anno_id)\n",
    "        no_anno += 1\n",
    "        continue\n",
    "\n",
    "    k = list(parsed_dict[\"concepts\"][hex_code][\"identifiers\"].keys())[0]\n",
    "    mcdict = parsed_dict['concepts'][hex_code]['identifiers'][k]\n",
    "    \n",
    "    if len(mcdict) == 1:\n",
    "        parsed_annotation['mi_anno'][anno_id]['concept_id'] = 0\n",
    "        print('0')\n",
    "    elif len(mcdict) > 1:\n",
    "        prompt_mcdict = []\n",
    "\n",
    "        index = 0\n",
    "        for val in mcdict:\n",
    "            prompt_mcdict.append({'index': f\"{index}\", 'identifier': f\"{match_variable}{'' if len(val['affixes']) == 0 else val['affixes'][0]}\", 'description': val['description']})\n",
    "            index += 1\n",
    "            \n",
    "        prompt = [\n",
    "            {'role': 'system', 'content': 'You are a professional annotater API. Your job is to select a fitting annotation from a dictionary for a mathematical identifier.'},\n",
    "            {'role': 'user', 'content': f'''Given the following possible annotations:\\n```json\\n{prompt_mcdict}```.\n",
    "             Select the index for the most fitting description for the identifier <<{match_variable}>> from the following text.\n",
    "             The potential affix of the indentifier could be <<{possible_affix}>>. Take the affixes of the possible annotations into account.\n",
    "             Only return the value of the index and nothing else.\n",
    "             Do not add any explanation otherwise the API breaks.\n",
    "             The identifier has been marked with <<>>.\n",
    "             If you can't come up with an index, write 'None'\n",
    "             ```txt\n",
    "             {context}\n",
    "             ```'''}\n",
    "        ]\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                open_prompt = get_prompt_anno(prompt)\n",
    "                \n",
    "                input_ids = tokenizer(open_prompt, return_tensors='pt').input_ids.cuda()\n",
    "                output = model.generate(inputs=input_ids, temperature=0.5, max_new_tokens=512, repetition_penalty=1.05)\n",
    "                output_string = tokenizer.decode(output[0])\n",
    "                \n",
    "                actual_total_tokens += num_tokens_from_messages(output_string)\n",
    "                completion_tokens += num_tokens_from_messages(output_string) - num_tokens_from_messages(open_prompt)\n",
    "                prompt_tokens += num_tokens_from_messages(open_prompt)\n",
    "\n",
    "                ind = output_string.index('ASSISTANT:')\n",
    "                value = output_string[ind:]\n",
    "                print(value)\n",
    "                \n",
    "                print(completion_tokens, prompt_tokens)\n",
    "\n",
    "                try:\n",
    "                    index = int(int(re.search('\\d+', value).group()))\n",
    "                    print(index)\n",
    "                    parsed_annotation['mi_anno'][anno_id]['concept_id'] = index\n",
    "                except Exception as f:\n",
    "                    print(f)\n",
    "\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Exception occurred\\n{e}\")\n",
    "                print(\"Retrying...\")\n",
    "    else:\n",
    "        print('None')\n",
    "\n",
    "print('Annotation completed')\n",
    "\n",
    "    \n",
    "total_time_taken = (datetime.now() - start_time)\n",
    "print(f\"Time taken: {datetime.now() - start_time }\")\n",
    "print(f\"Total time taken: {total_time_taken}\")\n",
    "print(actual_total_tokens, completion_tokens, prompt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfeab45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_annotation['_annotator'] = model_name_or_path\n",
    "with open(f'{file_code}-{model_name}_anno.json', 'w') as fp:\n",
    "    json.dump(parsed_annotation, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9180c363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n"
     ]
    }
   ],
   "source": [
    "items = 0\n",
    "for key, value in parsed_annotation['mi_anno'].items():\n",
    "    if value['concept_id'] is not None:\n",
    "        #print(key, value)\n",
    "        items += 1\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe4c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
